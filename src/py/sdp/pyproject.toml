[project]
name = "spark-declarative-pipelines-examples"
version = "0.1.0"
description = "Example implementations of Spark Declarative Pipelines (SDP) and LakeFlow Declarative Pipelines (LDP) with PySpark 4.1.0.dev1, featuring Daily Orders e-commerce, Oil Rigs sensor monitoring, and Music Analytics use cases"
readme = "SDP_README.md"
requires-python = ">=3.12"
authors = [
    {name = "Jules S. Damji", email = "jules.damji@databricks.com"}
]
keywords = ["spark", "pyspark", "spark-connect", "delta-live-tables", "data-pipelines", "etl", "analytics", "iot", "ecommerce", "music-analytics", "lakeflow"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Topic :: Scientific/Engineering :: Information Analysis",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.12",
]
dependencies = [
    "faker>=37.6.0",
    "plotly>=6.3.0",
    "kaleido>=0.2.0",
    "pillow>=10.0.0",
    "pyspark @ file:///Users/jules/pydist/pyspark-4.1.0.dev3.tar.gz",
    "pyspark-connect @ file:///Users/jules/pydist/pyspark_connect-4.1.0.dev3.tar.gz",
    "databricks-sdk>=0.12.0",
]

[project.urls]
Homepage = "https://github.com/dmatrix/etl-pipelines"
Repository = "https://github.com/dmatrix/etl-pipelines"
Documentation = "https://github.com/dmatrix/etl-pipelines/tree/main/src/py/sdp"

[project.optional-dependencies]
dev = [
    "pytest>=7.0",
    "black>=23.0",
    "flake8>=6.0",
    "mypy>=1.0",
]

[project.scripts]
sdp-daily-orders = "daily_orders.query_tables:main"
sdp-oil-rigs = "oil_rigs.query_oil_rigs_tables:main"

[build-system]
requires = ["setuptools>=45", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools]
packages = ["daily_orders", "oil_rigs", "utils"]

[tool.setuptools.package-data]
daily_orders = ["*.yml", "*.sql", "*.sh"]
oil_rigs = ["*.yml", "*.sql", "*.sh"]

[tool.uv]
dev-dependencies = []
